{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c109798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4/4/2024\n",
    "\n",
    "# Q1 i) Generate Word Context matrix for a given Corpus on a specifed window Size\n",
    "#   ii) Find Similarity b/w two words using Word Content matrix\n",
    "\n",
    "# Q2 i) Generate word vectors using word to Vec library on IMDB data set.\n",
    "#   ii) Implement text classification Using Word2Vec and LSTM.\n",
    "\n",
    "# Q3 i) Generate word embeddings using BERT library on IMDB dataset.\n",
    "#   ii) Implement text classification Using BERT embeddings and BERT classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fec27282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    new_corpus = []\n",
    "    for i,docs in enumerate(corpus):\n",
    "        corpus[i]=\"\".join(ch for ch in docs if ch.isalnum() or ch ==' ')\n",
    "        new_corpus.append([w.lower() for w in corpus[i].split()])\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b9264a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocab(corpus):\n",
    "    vocab = set()\n",
    "    for c in corpus:\n",
    "        vocab.update(c)\n",
    "    v = {words:i for i,words in enumerate(vocab)}\n",
    "    return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "78c96591",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I I like to eat apples and bananas.\",\n",
    "    \"Apples are delicious fruits.\",\n",
    "    \"Bananas are yellow in color.\",\n",
    "    \"I like to code in Python.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "486cae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_content_matrix(corpus,window_size):\n",
    "    corpus = preprocess(corpus)\n",
    "    vocab = getVocab(corpus)\n",
    "#     print(corpus,vocab)\n",
    "    \n",
    "    word_list_len = len(vocab)\n",
    "    \n",
    "    word_context_matrix = np.zeros((word_list_len, word_list_len))\n",
    "    \n",
    "    for target_word,row in vocab.items():\n",
    "#         print(target_word,row)\n",
    "        for docs in corpus:\n",
    "            for i,word1 in enumerate(docs):\n",
    "                if word1 == target_word:\n",
    "                    for j in range (i+1, min(i+window_size+1, len(docs))):\n",
    "                        word_context_matrix[row][vocab[docs[j]]]+=1\n",
    "                    for j in range (max(i-window_size,0),i):\n",
    "                        word_context_matrix[row][vocab[docs[j]]]+=1\n",
    "                        \n",
    "    return word_context_matrix,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e654ef19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 2., 0., 0., 0., 0., 0., 3., 2., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 2., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 2., 0., 0., 0., 0., 0., 2., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix,vocab = word_content_matrix(corpus,2)\n",
    "word_context_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1f14e593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 0,\n",
       " 'fruits': 1,\n",
       " 'in': 2,\n",
       " 'i': 3,\n",
       " 'delicious': 4,\n",
       " 'are': 5,\n",
       " 'bananas': 6,\n",
       " 'and': 7,\n",
       " 'yellow': 8,\n",
       " 'like': 9,\n",
       " 'to': 10,\n",
       " 'code': 11,\n",
       " 'apples': 12,\n",
       " 'python': 13,\n",
       " 'eat': 14}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9722b4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>fruits</th>\n",
       "      <th>in</th>\n",
       "      <th>i</th>\n",
       "      <th>delicious</th>\n",
       "      <th>are</th>\n",
       "      <th>bananas</th>\n",
       "      <th>and</th>\n",
       "      <th>yellow</th>\n",
       "      <th>like</th>\n",
       "      <th>to</th>\n",
       "      <th>code</th>\n",
       "      <th>apples</th>\n",
       "      <th>python</th>\n",
       "      <th>eat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delicious</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bananas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           color  fruits   in    i  delicious  are  bananas  and  yellow  \\\n",
       "color        0.0     0.0  1.0  0.0        0.0  0.0      0.0  0.0     1.0   \n",
       "fruits       0.0     0.0  0.0  0.0        1.0  1.0      0.0  0.0     0.0   \n",
       "in           1.0     0.0  0.0  0.0        0.0  1.0      0.0  0.0     1.0   \n",
       "i            0.0     0.0  0.0  2.0        0.0  0.0      0.0  0.0     0.0   \n",
       "delicious    0.0     1.0  0.0  0.0        0.0  1.0      0.0  0.0     0.0   \n",
       "are          0.0     1.0  1.0  0.0        1.0  0.0      1.0  0.0     1.0   \n",
       "bananas      0.0     0.0  0.0  0.0        0.0  1.0      0.0  1.0     1.0   \n",
       "and          0.0     0.0  0.0  0.0        0.0  0.0      1.0  0.0     0.0   \n",
       "yellow       1.0     0.0  1.0  0.0        0.0  1.0      1.0  0.0     0.0   \n",
       "like         0.0     0.0  0.0  3.0        0.0  0.0      0.0  0.0     0.0   \n",
       "to           0.0     0.0  1.0  2.0        0.0  0.0      0.0  0.0     0.0   \n",
       "code         0.0     0.0  1.0  0.0        0.0  0.0      0.0  0.0     0.0   \n",
       "apples       0.0     0.0  0.0  0.0        1.0  1.0      1.0  1.0     0.0   \n",
       "python       0.0     0.0  1.0  0.0        0.0  0.0      0.0  0.0     0.0   \n",
       "eat          0.0     0.0  0.0  0.0        0.0  0.0      0.0  1.0     0.0   \n",
       "\n",
       "           like   to  code  apples  python  eat  \n",
       "color       0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "fruits      0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "in          0.0  1.0   1.0     0.0     1.0  0.0  \n",
       "i           3.0  2.0   0.0     0.0     0.0  0.0  \n",
       "delicious   0.0  0.0   0.0     1.0     0.0  0.0  \n",
       "are         0.0  0.0   0.0     1.0     0.0  0.0  \n",
       "bananas     0.0  0.0   0.0     1.0     0.0  0.0  \n",
       "and         0.0  0.0   0.0     1.0     0.0  1.0  \n",
       "yellow      0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "like        0.0  2.0   1.0     0.0     0.0  1.0  \n",
       "to          2.0  0.0   1.0     1.0     0.0  1.0  \n",
       "code        1.0  1.0   0.0     0.0     1.0  0.0  \n",
       "apples      0.0  1.0   0.0     0.0     0.0  1.0  \n",
       "python      0.0  0.0   1.0     0.0     0.0  0.0  \n",
       "eat         1.0  1.0   0.0     1.0     0.0  0.0  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "temp_mat = []\n",
    "    \n",
    "for v,i in vocab.items():\n",
    "    counts = {v2: 0 for v2 in vocab.items()}\n",
    "    for v2,j  in vocab.items():\n",
    "        counts[v2] = word_context_matrix[i][j]\n",
    "    temp_mat.append(counts)\n",
    "\n",
    "df = pd.DataFrame(temp_mat,columns=vocab.keys(),index=vocab.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fff09c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(word1, word2, vocab, word_content_matrix):\n",
    "    if word1 not in vocab or word2 not in vocab:\n",
    "        return \"One or both words not found in the corpus.\"\n",
    "    \n",
    "    index1 = vocab[word1]\n",
    "    index2 = vocab[word2]\n",
    "    \n",
    "    similarity = np.dot(word_content_matrix[index1], word_content_matrix[index2]) / (np.linalg.norm(word_content_matrix[index1]) * np.linalg.norm(word_content_matrix[index2]))\n",
    "    \n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f8f0a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4082482904638631"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity('apples','bananas',vocab,word_context_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6505f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp38-cp38-macosx_10_9_x86_64.whl (24.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.1 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from gensim) (6.4.0)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 35.0 MB 6.5 MB/s eta 0:00:013\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.22.4)\n",
      "Installing collected packages: scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed gensim-4.3.2 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "# Q2 i) Generate word vectors using word to Vec library on IMDB data set.\n",
    "#   ii) Implement text classification Using Word2Vec and LSTM.\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2ff954a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: click in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from nltk) (8.0.1)\r\n",
      "Requirement already satisfied: joblib in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\r\n",
      "Requirement already satisfied: regex in /Users/uzmafirozkhan/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1c7ee656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url):\n",
    "#     url = \"https://en.wikipedia.org/wiki/Taylor_Swift\"\n",
    "    page = urlopen(url)\n",
    "    page = page.read().decode(\"utf-8\")\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b6d0d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(page):\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    clean_soup = soup.get_text()\n",
    "    \n",
    "    whitespaces = re.compile(\"\\n[\\n]+\\n\")\n",
    "    refs = re.compile(\"\\[.*?\\]\")\n",
    "    page = re.sub(whitespaces, \"\\n\", clean_soup)\n",
    "    page = re.sub(refs, \" \", page)\n",
    "    \n",
    "    paras = [\"\".join(list(s.strings)).strip()+\"\\n\" for s in soup.find_all('p')]\n",
    "    paras = [s for s in paras if s != \"\\n\"] # paras\n",
    "    cleaned_text = [s for s in paras if s!=\"\\n\"]\n",
    "    cleaned_text = \"\\n\".join(cleaned_text)\n",
    "    return cleaned_text[5000:5200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9b6e6d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iting an original song22 in 2003 swift and her parents started working with the talent manager dan dymtrow with his help swift modeled for abercrombie  fitch and had an original song included o'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = preProcess(getPage(\"https://en.wikipedia.org/wiki/Taylor_Swift\"))\n",
    "# remove punctuations\n",
    "corpus=\"\".join(ch.lower() for ch in corpus if ch.isalnum() or ch==' ')\n",
    "\n",
    "# corpus = [w.lower() for w in corpus.split()]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a8059aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Preprocess the dataset\n",
    "corpus = [word_tokenize(doc) for doc in dataset]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"word2vec_imdb.model\")\n",
    "\n",
    "# Example usage\n",
    "word = \"king\"\n",
    "similar_words = model.wv.most_similar(word)\n",
    "print(f\"Words similar to '{word}': {similar_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "88d3f04d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-b3f4025d031f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the IMDB dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Dataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Load the IMDB dataset\n",
    "dataset = api.load(\"text8\")\n",
    "dataset[:10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
